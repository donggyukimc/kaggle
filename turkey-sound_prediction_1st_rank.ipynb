{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#https://www.kaggle.com/c/dont-call-me-turkey \n\n\n\n This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import json\nwith open(\"../input/train.json\") as f :\n    df_train = pd.DataFrame(json.load(f))\nwith open(\"../input/test.json\") as f :\n    df_test = pd.DataFrame(json.load(f))\nprint(\"train data:\", df_train.shape)\nprint(\"test data:\", df_test.shape)\n\nprint(\"data columns\")\nprint(\"train: \", list(df_train.columns))\nprint(\"test: \", list(df_test.columns))\nmax_frame_seq = df_train['audio_embedding'].apply(lambda x : len(x)).max()\nprint(\"max frame sequence : \", max_frame_seq)\n\nprint(\"is not turkey : \", df_train[df_train['is_turkey'] == 0]['is_turkey'].count())\nprint(\"is turkey : \", df_train[df_train['is_turkey'] == 1]['is_turkey'].count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf6a3dda12075a2f2c87247bec9d13f4a50f486f"},"cell_type":"code","source":"import re\nimport lxml\nfrom lxml import etree\nimport requests\nfrom dask import bag\n\ndef get_title(vid) :\n    try : return etree.HTML(requests.get(\"http://www.youtube.com/watch?v=\" + vid).text).xpath(\"//span[@id='eow-title']/@title\")[0]\n    except : return ''\ndf_train['title'] = list(bag.from_sequence(df_train['vid_id'].values).map(get_title))\ndf_test['title'] = list(bag.from_sequence(df_test['vid_id'].values).map(get_title))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a70a8e344712f381782872a6af4522fbea7867d"},"cell_type":"code","source":"def process_title(title) :\n    title = re.sub('[^ A-Za-z]', '', title)\n    title = title.strip()\n    title = title.lower()\n    return title\ndf_train['title'] = list(bag.from_sequence(df_train['title'].values).map(process_title))\ndf_test['title'] = list(bag.from_sequence(df_test['title'].values).map(process_title))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23e6197058893cc9dcb14e67736173298a894afe"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom nltk.corpus import stopwords\ntrain, validate = train_test_split(df_train)\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\ndf_all = pd.DataFrame()\ndf_all['title'] = pd.concat([df_train['title'], df_test['title']])\ntokenizer = Tokenizer(num_words = 20)\ntokenizer.fit_on_texts(list(df_all['title'].values))\nstopWords = set(stopwords.words('english'))\nlow_count_words = [w for w,c in tokenizer.word_counts.items() if c < 5 or w in stopWords]\nfor w in low_count_words:\n    del tokenizer.word_index[w]\n    del tokenizer.word_docs[w]\n    del tokenizer.word_counts[w]\ntrain_title    = tokenizer.texts_to_sequences(train['title'])\nvalidate_title = tokenizer.texts_to_sequences(validate['title'])\ntest_title     = tokenizer.texts_to_sequences(df_test['title'])\ntrain_train_title = tokenizer.texts_to_sequences(df_train['title'])\n\nword_index = tokenizer.word_index\nword_num = len(word_index)\nprint(word_num)\n\nmax_words = max(max([len(title) for title in train_train_title]), max([len(title) for title in test_title]))\nprint(max_words)\n\ntrain_title    = pad_sequences(train_title, maxlen=max_words)\nvalidate_title = pad_sequences(validate_title, maxlen=max_words)\ntest_title     = pad_sequences(test_title, maxlen=max_words)\ntrain_train_title = pad_sequences(train_train_title, maxlen=max_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ab309ed166d06ec58884a88bbaa5c8e0a5d08ec"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain, validate = train_test_split(df_train)\ntrain_x = train['audio_embedding'].values\ntrain_y = train['is_turkey'].values\n\nvalidate_x = validate['audio_embedding'].values\nvalidate_y = validate['is_turkey'].values\n\ntrain_train_x = df_train['audio_embedding'].values\ntrain_train_y = df_train['is_turkey'].values\n\ntest_x = df_test['audio_embedding'].values\n\nfrom keras.preprocessing.sequence import pad_sequences\n\ntrain_x       = pad_sequences(train_x, maxlen = max_frame_seq) / 255\nvalidate_x    = pad_sequences(validate_x, maxlen = max_frame_seq) / 255\ntrain_train_x = pad_sequences(train_train_x, maxlen = max_frame_seq) / 255\ntest_x        = pad_sequences(test_x, maxlen = max_frame_seq) / 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7e0673e434fd12f353da35d6a54aae0f2914ac0"},"cell_type":"code","source":"from keras import backend as K\nfrom keras.engine.topology import Layer\nfrom keras import initializers, regularizers, constraints, optimizers, layers\n\n# https://www.kaggle.com/suicaokhoailang/lstm-attention-baseline-0-652-lb\nclass Attention(Layer):\n    def __init__(self, step_dim,\n                 W_regularizer=None, b_regularizer=None,\n                 W_constraint=None, b_constraint=None,\n                 bias=True, **kwargs):\n        self.supports_masking = True\n        self.init = initializers.get('glorot_uniform')\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        self.step_dim = step_dim\n        self.features_dim = 0\n        super(Attention, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 3\n\n        self.W = self.add_weight((input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_W'.format(self.name),\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        self.features_dim = input_shape[-1]\n\n        if self.bias:\n            self.b = self.add_weight((input_shape[1],),\n                                     initializer='zero',\n                                     name='{}_b'.format(self.name),\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n        else:\n            self.b = None\n\n        self.built = True\n\n    def compute_mask(self, input, input_mask=None):\n        return None\n\n    def call(self, x, mask=None):\n        features_dim = self.features_dim\n        step_dim = self.step_dim\n\n        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n\n        if self.bias:\n            eij += self.b\n\n        eij = K.tanh(eij)\n\n        a = K.exp(eij)\n\n        if mask is not None:\n            a *= K.cast(mask, K.floatx())\n\n        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n\n        a = K.expand_dims(a)\n        weighted_input = x * a\n        return K.sum(weighted_input, axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0],  self.features_dim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6cc614708df59e6260d2fe434499949080459c16","scrolled":true},"cell_type":"code","source":"from keras.models import Model, Sequential\nfrom keras.layers import Dense, Input, LSTM, Bidirectional, Dropout, BatchNormalization, Flatten, concatenate, Activation, Embedding, CuDNNLSTM, GRU, CuDNNGRU, Embedding\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint\n\ndropout = 0.4\nembedding_size = 3\ninp_word = Input(shape=(max_words, ))\nembedding = Embedding(word_num, embedding_size, input_length = max_words)(inp_word)\nx1 = BatchNormalization()(embedding)\nx1 = Bidirectional(CuDNNGRU(128, return_sequences=True))(x1)\nx1 = Attention(max_words)(x1)\n\ninp = Input(shape=(max_frame_seq, 128))\nx2 = BatchNormalization(input_shape=(10, 128))(inp)\nx2 = Bidirectional(CuDNNGRU(128, return_sequences=True))(x2)\nx2 = Attention(max_frame_seq)(x2)\n\nx = concatenate([x1, x2])\nx = Dense(1, activation=\"sigmoid\")(x)\nmodel = Model(inputs=[inp_word, inp], outputs=x)\nadam = Adam(lr=0.001)\nmodel.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n\nfilepath=\"improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\ncallbacks_list = [checkpoint]\nbest_epoch = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c57f46c0bb847957e4727d09153a987e2b4e189d","scrolled":false},"cell_type":"code","source":"#model.fit([train_title, train_x], train_y, batch_size=512, epochs=100, validation_data=([validate_title, validate_x], validate_y), callbacks=callbacks_list, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c66018d9b2c0dc189cd8338493e1d680f7a32d4c"},"cell_type":"code","source":"\"\"\"\n#fit on a portion of the training data, and validate on the rest\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=2, verbose=1, min_lr=1e-8)\n# reduce_lr1 = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)\n\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\n# reduce_lr = ReduceLROnPlateau(monitor='val_loss', verbose=1, factor=0.1, patience=10, min_lr=0.0001)\nearly_stop = EarlyStopping(monitor='val_loss', verbose=1, patience=20,  restore_best_weights=True)\n\n# History  = model.fit(x_train, y_train,batch_size=32,epochs=100,validation_data=(x_val, y_val),callbacks=[reduce_lr,early_stop])\nHistory  = model.fit(x_train, y_train,batch_size=512, epochs=16,validation_data=[x_val, y_val],verbose = 2,callbacks=[reduce_lr,early_stop])\neva_plot(History)\n# Get accuracy of model on validation data. It's not AUC but it's something at least!\nscore, acc = model.evaluate(x_val, y_val, batch_size=256)\nprint('Test accuracy:', acc)\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"e65d45d8a73ab7bdfef81416e1659a10e358494d"},"cell_type":"code","source":"model.fit([train_train_title, train_train_x], train_train_y, batch_size=512, epochs=21)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"2477a6430b97093eb897998675ecf85a286d5c87"},"cell_type":"code","source":"predict = model.predict([test_title, test_x])\nsubmission = pd.DataFrame()\nsubmission['vid_id'] = df_test['vid_id']\nsubmission['is_turkey'] = predict\nsubmission.to_csv('csv_to_submit.csv', index = False)\nprint(submission.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d017cab7ecde5d4d28ed1dea6d5b40bc70e94c8"},"cell_type":"code","source":"\"\"\"\nimport tensorflow as tf\nimport random\nfrom sklearn.metrics import accuracy_score\n\nenc_layer_size = [128]\nenc_layer_num = len(enc_layer_size)\n\ntf.reset_default_graph()\ntf_dropout = tf.placeholder(shape = None, dtype = tf.float32)\nseq = tf.placeholder(shape = None, dtype = tf.int32)\n\nx = tf.placeholder(tf.float32, [None, max_frame_seq, 128])  \ntarget = tf.placeholder(tf.float32, [None, 1])\ninp = tf.layers.batch_normalization(x)\nfw_enc_cells = [tf.contrib.rnn.LSTMCell(\n                                            num_units = layer_size\n                                            , activation = tf.nn.relu\n                                            )\n                    for layer_size in enc_layer_size]\nfw_enc_cells = [tf.contrib.rnn.DropoutWrapper(\n                                            enc_cell\n                                            , output_keep_prob = 1.0 - tf_dropout\n                                            , state_keep_prob = 1.0 - tf_dropout\n                                            ) for enc_cell in fw_enc_cells]\nfw_enc_cells = tf.contrib.rnn.MultiRNNCell(fw_enc_cells)\nbw_enc_cells = [tf.contrib.rnn.LSTMCell(\n                                            num_units = layer_size\n                                            , activation = tf.nn.relu\n                                            )\n                    for layer_size in enc_layer_size]\nbw_enc_cells = [tf.contrib.rnn.DropoutWrapper(\n                                            enc_cell\n                                            , output_keep_prob = 1.0 - tf_dropout\n                                            , state_keep_prob = 1.0 - tf_dropout\n                                            ) for enc_cell in bw_enc_cells]\nbw_enc_cells = tf.contrib.rnn.MultiRNNCell(bw_enc_cells)\noutputs, (fw_enc_state, bw_enc_state) = tf.nn.bidirectional_dynamic_rnn(fw_enc_cells, bw_enc_cells\n                                            , inp, sequence_length = seq, time_major = False, dtype = tf.float32)\nu_omega = tf.Variable(tf.random_normal([2], stddev=0.1))\noutput = tf.concat(outputs, 2)\n#output = tf.sum(outputs, 2)\nv = tf.nn.tanh(tf.layers.dense(inputs = output, units = 2))\nvu = tf.tensordot(v, u_omega, axes=1, name='vu')\nalphas = tf.nn.softmax(vu, name='alphas')\nattention_vector = tf.reduce_sum(output * tf.expand_dims(alphas, -1), 1)\noutput = attention_vector\n\noutput = tf.layers.dense(\n    inputs = output\n    , units = 1\n    , activation = None)\n\npredict = tf.nn.sigmoid(output)\nloss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = target, logits = output))\n        \nlearning_rate = tf.placeholder(shape = None, dtype = tf.float32)\noptimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)\n\nsession = tf.Session()\nsession.run(tf.global_variables_initializer())\n\nbatch_size = 300\nepoch = 1000\nfor i in range(epoch) :\n    idx = [i for i in range(train_x.shape[0])]\n    batch_idx = random.sample(idx, batch_size)\n    feed_dict = {\n        x : train_x[batch_idx]\n        , target : train_y[batch_idx].reshape(-1, 1)\n        , tf_dropout : 0.4\n        , learning_rate : 0.001\n        , seq : train_x_seq[batch_idx]\n    }\n    l, p, _ = session.run([loss, predict, optimizer], feed_dict = feed_dict)\n    feed_dict = {\n        x : validate_x\n        , target : validate_y.reshape(-1, 1)\n        , tf_dropout : 0.0\n        , seq : validate_x_seq\n    }\n    l, p = session.run([loss, predict], feed_dict = feed_dict)\n    acc = accuracy_score(validate_y == 1, p > 0.5)\n    print(i, '\\t', \"{0:.4f}\".format(l), '\\t', \"{0:.4f}\".format(acc))\n    \nfeed_dict = {\n    x : test_x\n    #, target : validate_y.reshape(-1, 1)\n    , tf_dropout : 0.0\n    , seq : test_x_seq\n}\n\np = session.run([predict], feed_dict = feed_dict)\nsubmission = pd.DataFrame()\nsubmission['vid_id'] = df_test['vid_id']\nsubmission['is_turkey'] = p[0]\nsubmission.to_csv('csv_to_submit.csv', index = False)\nprint(submission)\n\"\"\"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}
